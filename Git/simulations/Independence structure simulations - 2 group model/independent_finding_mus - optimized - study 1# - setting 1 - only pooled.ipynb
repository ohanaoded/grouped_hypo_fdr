{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39188e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy.linalg import sqrtm\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import statistics\n",
    "\n",
    "import numba\n",
    "from numba import jit, njit\n",
    "from numba.typed import List\n",
    "\n",
    "import independent_functions as i_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a25032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdep_marginals_pooled_ruth(alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1, musMargFDR):\n",
    "\n",
    "    block_beta_agg = []\n",
    "    \n",
    "    #  columns order: marglocfdrFDR, marglocfdrpFDR, marglocfdrmFDR\n",
    "    minprob_mat = np.zeros((1,6),float)\n",
    "    lev_mat = np.zeros((1,6),float) \n",
    "    pow_mat = np.zeros((1,6),float) \n",
    "    ev_mat = np.zeros((1,6),float) \n",
    "    er_mat = np.zeros((1,6),float) \n",
    "    \n",
    "    \n",
    "    for i in range(len(mu0)):\n",
    "        # - - - BLOCK BETA - - - creating vector Z from each group, but straight afterwards - concating it\n",
    "        block_beta = i_f.my_rbeta(num_hypo[i], \n",
    "                                prob_to_1[i], \n",
    "                                mu0[i], \n",
    "                                mu1[i], \n",
    "                                variance_0[i], \n",
    "                                variance_1[i],\n",
    "                                False)\n",
    "        block_beta_agg.append(block_beta)\n",
    "        \n",
    "    # concating the Z vectors to a one coherent vector\n",
    "    block_beta_agg_stacked = np.hstack(block_beta_agg)   \n",
    "    \n",
    "    # - - - creating locfdr for the pooled rule - - -\n",
    "    \n",
    "    ### NUMERATOR\n",
    "    first_group_prob = (num_hypo[0])/(num_hypo[0]+num_hypo[1])\n",
    "    second_group_prob = (num_hypo[1])/(num_hypo[0]+num_hypo[1])\n",
    "    Ph0 = (1-prob_to_1[0])*(first_group_prob) + (1-prob_to_1[1])*(second_group_prob)\n",
    "    # Assuming that both null distributions in the 2 groups are the same (mu0 & variance0 has the same values in their 2 indexes of groups), other wise, needed to change to the same logic of partition as Ph0\n",
    "    dist_0 = stats.norm(mu0[0], np.sqrt(variance_0[0]))\n",
    "    Pzh0 = dist_0.pdf(block_beta_agg_stacked)\n",
    "\n",
    "    NUMERATOR = Pzh0*Ph0\n",
    "\n",
    "\n",
    "    ### DENOMINATOR\n",
    "    Ph1c1 = prob_to_1[0]*first_group_prob\n",
    "    Ph1c2 = prob_to_1[1]*second_group_prob\n",
    "\n",
    "    dist_1_1 = stats.norm(mu1[0], np.sqrt(variance_1[0]))\n",
    "    Pzh1c1 = dist_1_1.pdf(block_beta_agg_stacked)\n",
    "    dist_1_2 = stats.norm(mu1[1], np.sqrt(variance_1[1]))\n",
    "    Pzh1c2 = dist_1_2.pdf(block_beta_agg_stacked)\n",
    "\n",
    "    DENOMINATOR = NUMERATOR + Pzh1c1*Ph1c1 + Pzh1c2*Ph1c2\n",
    "\n",
    "\n",
    "    ### marglocfdr\n",
    "    marglocfdr = NUMERATOR / DENOMINATOR\n",
    "    \n",
    "    \n",
    "    # - - - creating a marginal & b marginal - - - \n",
    "    omarglocfdr = np.sort(marglocfdr)\n",
    "    amarg = 1 - omarglocfdr\n",
    "    omarglocfdr_numba = numba.typed.List(omarglocfdr)    \n",
    "    bmarg = np.array(i_f.BZCpp_numba_jit(omarglocfdr_numba)) # it WAS np.array but now it's a LIST of np.arrays so that when you take an index from it, it will be fine\n",
    "    \n",
    "    # marglocfdrFDR \n",
    "    lev_mat, pow_mat, minprob_mat, ev_mat, er_mat = i_f.FDR_Generic_structure (mus=musMargFDR, a=amarg, b_1=bmarg, \n",
    "                                                                               b_2=bmarg, ind=3, \n",
    "                                                                               lev_mat=lev_mat, \n",
    "                                                                               pow_mat=pow_mat, \n",
    "                                                                               minprob_mat=minprob_mat, \n",
    "                                                                               ev_mat=ev_mat, \n",
    "                                                                               er_mat=er_mat,  \n",
    "                                                                               olocfdr_function=omarglocfdr, \n",
    "                                                                               alpha = alpha)\n",
    "\n",
    "    return lev_mat, pow_mat, minprob_mat, ev_mat, er_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b02623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#musMargFDR_scalar = [1425.5]   # between 1432.3160887391211 to 1419.\n",
    "alpha = 0.1\n",
    "\n",
    "# Cai & sun 09' setting - Study 1# --- 1\n",
    "# All of the relevant constants, BUT the one that varies\n",
    "\n",
    "num_hypo = [300, 150] # before optimization: [3000, 1500]\n",
    "\n",
    "mu0 = [0, 0]\n",
    "mu1 = [-2, 4]\n",
    "\n",
    "variance_0 = [1, 1]\n",
    "variance_1 = [1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5be6edee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_to_1 = [0.03, 0.1]\n",
    "# prob_to_1 = [0.15, 0.1]\n",
    "# prob_to_1 = [0.27, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8201fc90",
   "metadata": {},
   "source": [
    "# finding unit root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed86638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_marg_pooled_FDR(mu_FDR_variable, iter_num, alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1):\n",
    "    start = time.time()\n",
    "    lev_mat_agg = 0\n",
    "    pow_mat_agg = 0\n",
    "    minprob_mat_agg = 0\n",
    "    ev_mat_agg = 0\n",
    "    er_mat_agg = 0\n",
    "    \n",
    "    for i in range(iter_num):\n",
    "        if i == 1000:\n",
    "            print(\"this is iteration no. 1000\")\n",
    "        if i == 4000:\n",
    "            print(\"this is iteration no. 4000\")\n",
    "            \n",
    "            \n",
    "        lev_mat, pow_mat, minprob_mat, ev_mat, er_mat = fdep_marginals_pooled_ruth(alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1, \n",
    "                                                                                [mu_FDR_variable])\n",
    "        lev_mat_agg += lev_mat[0]\n",
    "        pow_mat_agg += pow_mat[0]\n",
    "        minprob_mat_agg += minprob_mat[0]\n",
    "        ev_mat_agg += ev_mat[0]\n",
    "        er_mat_agg += er_mat[0]\n",
    "        \n",
    "    # R & S RETURN\n",
    "    pow_mat_r = pow_mat_agg / iter_num\n",
    "    lev_mat_r = lev_mat_agg / iter_num\n",
    "    ev_mat_r = ev_mat_agg / iter_num\n",
    "    er_mat_r = er_mat_agg / iter_num\n",
    "    minprob_mat_r = minprob_mat_agg / iter_num\n",
    "\n",
    "    print(\"This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \")\n",
    "    print(mu_FDR_variable)\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    print(f\"Time this {iter_num} iteration run took: \" + str(duration))\n",
    "    print(\"This is the calculation right now, aiming for 0: \")\n",
    "    print(lev_mat_r[3] - alpha)\n",
    "    \n",
    "    \n",
    "    return(lev_mat_r[3] - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "86c52e76",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "17.0\n",
      "Time this 5000 iteration run took: 77.39853811264038\n",
      "This is the calculation right now, aiming for 0: \n",
      "0.04276275964758086\n",
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "25.0\n",
      "Time this 5000 iteration run took: 82.20987248420715\n",
      "This is the calculation right now, aiming for 0: \n",
      "-0.018242772878612493\n",
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "22.60772216903052\n",
      "Time this 5000 iteration run took: 78.29210209846497\n",
      "This is the calculation right now, aiming for 0: \n",
      "-0.005944278592142291\n",
      "this is iteration no. 1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\optimize\\zeros.py\u001b[0m in \u001b[0;36mbrentq\u001b[1;34m(f, a, b, args, xtol, rtol, maxiter, full_output, disp)\u001b[0m\n\u001b[0;32m    774\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrtol\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0m_rtol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"rtol too small (%g < %g)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rtol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 776\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_zeros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_brentq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    777\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults_c\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12668/4033225887.py\u001b[0m in \u001b[0;36mfunc_marg_pooled_FDR\u001b[1;34m(mu_FDR_variable, iter_num, alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         lev_mat, pow_mat, minprob_mat, ev_mat, er_mat = fdep_marginals_pooled_ruth(alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1, \n\u001b[0m\u001b[0;32m     17\u001b[0m                                                                                 [mu_FDR_variable])\n\u001b[0;32m     18\u001b[0m         \u001b[0mlev_mat_agg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlev_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12668/14521169.py\u001b[0m in \u001b[0;36mfdep_marginals_pooled_ruth\u001b[1;34m(alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1, musMargFDR)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmu0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m# - - - BLOCK BETA - - - creating vector Z from each group, but straight afterwards - concating it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         block_beta = i_f.my_rbeta(num_hypo[i], \n\u001b[0m\u001b[0;32m     16\u001b[0m                                 \u001b[0mprob_to_1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                 \u001b[0mmu0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Thesis\\simulations\\Independence structure simulations - 2 group model\\simulations_folder\\finding_mus_optimized\\independent_functions.py\u001b[0m in \u001b[0;36mmy_rbeta\u001b[1;34m(num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1, with_h)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# Z & vector h\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mZ_vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_hypo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mvec_h\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprob_to_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_hypo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iter_num = 5000 \n",
    "\n",
    "prob_to_1 = [0.03, 0.1]\n",
    "\n",
    "root_pooled_FDR = scipy.optimize.brentq(f=func_marg_pooled_FDR, a=17, b=25, args=(iter_num, alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1))#, maxiter=17, disp=False) \n",
    "root_pooled_FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fed63c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "85.0\n",
      "Time this 5000 iteration run took: 76.82020592689514\n",
      "This is the calculation right now, aiming for 0: \n",
      "0.035590381129453036\n",
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "115.0\n",
      "Time this 5000 iteration run took: 77.31794881820679\n",
      "This is the calculation right now, aiming for 0: \n",
      "-0.0220129723766741\n",
      "this is iteration no. 1000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iter_num = 5000 \n",
    "\n",
    "prob_to_1 = [0.15, 0.1]\n",
    "\n",
    "root_pooled_FDR = scipy.optimize.brentq(f=func_marg_pooled_FDR, a=85, b=115, args=(iter_num, alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1))#, maxiter=17, disp=False) \n",
    "root_pooled_FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c980cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "190.0\n",
      "Time this 5000 iteration run took: 82.9924488067627\n",
      "This is the calculation right now, aiming for 0: \n",
      "0.015358289019904325\n",
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "225.0\n",
      "Time this 5000 iteration run took: 82.90010499954224\n",
      "This is the calculation right now, aiming for 0: \n",
      "-0.01119981676795724\n",
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "210.2401526671505\n",
      "Time this 5000 iteration run took: 82.46109986305237\n",
      "This is the calculation right now, aiming for 0: \n",
      "-0.001534851692168021\n",
      "this is iteration no. 1000\n",
      "this is iteration no. 4000\n",
      "This is MU now!@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: \n",
      "208.10916748292573\n",
      "Time this 5000 iteration run took: 82.1406192779541\n",
      "This is the calculation right now, aiming for 0: \n",
      "0.0002299693818163251\n",
      "this is iteration no. 1000\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "iter_num = 5000 \n",
    "\n",
    "prob_to_1 = [0.27, 0.1]\n",
    "\n",
    "root_pooled_FDR = scipy.optimize.brentq(f=func_marg_pooled_FDR, a=190, b=225, args=(iter_num, alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1))#, maxiter=17, disp=False) \n",
    "root_pooled_FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e25c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941de998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37473374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1928f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4d7e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171e055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e1ecba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe1e1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1590efd9",
   "metadata": {},
   "source": [
    "# - - - backup: the new locfdr creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba8dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "### NUMERATOR\n",
    "\n",
    "first_group_prob = (num_hypo[0])/(num_hypo[0]+num_hypo[1])\n",
    "second_group_prob = (num_hypo[1])/(num_hypo[0]+num_hypo[1])\n",
    "Ph0 = (1-prob_to_1[0])*(first_group_prob) + (1-prob_to_1[1])*(second_group_prob)\n",
    "# Assuming that both null distributions in the 2 groups are the same (mu0 & variance0 has the same values in their 2 indexes of groups), other wise, needed to change to the same logic of partition as Ph0\n",
    "dist_0 = stats.norm(mu0[0], np.sqrt(variance_0[0]))\n",
    "Pzh0 = dist_0.pdf(block_beta_agg_stacked)\n",
    "\n",
    "NUMERATOR = Pzh0*Ph0\n",
    "\n",
    "\n",
    "### DENOMINATOR\n",
    "\n",
    "Ph1c1 = prob_to_1[0]*first_group_prob\n",
    "Ph1c2 = prob_to_1[1]*second_group_prob\n",
    "\n",
    "dist_1_1 = stats.norm(mu1[0], np.sqrt(variance_1[0]))\n",
    "Pzh1c1 = dist_1_1.pdf(block_beta_agg_stacked)\n",
    "dist_1_2 = stats.norm(mu1[1], np.sqrt(variance_1[1]))\n",
    "Pzh1c2 = dist_1_2.pdf(block_beta_agg_stacked)\n",
    "\n",
    "DENOMINATOR = NUMERATOR + Pzh1c1*Ph1c1 + Pzh1c2*Ph1c2\n",
    "\n",
    "\n",
    "### marglocfdr\n",
    "marglocfdr = NUMERATOR / DENOMINATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "589daa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lev_mat, pow_mat, minprob_mat, ev_mat, er_mat = fdep_marginals_pooled_ruth(alpha, num_hypo, prob_to_1, mu0, mu1, variance_0, variance_1, musMargFDR_scalar)\n",
    "# lev_mat, pow_mat, minprob_mat, ev_mat, er_mat "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
